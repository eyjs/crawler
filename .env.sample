# =================================================================
#  LLM Crawler Agent - 환경 변수 설정 예시 (.env.sample)
# =================================================================
# 이 파일의 이름을 .env 로 변경한 후, 각 설정을 자신의 환경에 맞게 수정하여 사용하세요.

# --- [필수] LLM 제공자 설정 ---
# 분석에 사용할 LLM 제공자를 선택합니다. ('local' 또는 'gemini')
# local: Ollama를 통해 로컬에서 실행되는 모델 (예: Llama 3)
# gemini: Google AI Studio의 Gemini 모델 (API 키 필요)
LLM_PROVIDER="local"


# --- [API 사용 시 필수] ---
# LLM_PROVIDER를 'gemini'로 설정했을 경우, 아래에 Google AI Studio에서 발급받은 API 키를 입력하세요.
GEMINI_API_KEY="YOUR_GOOGLE_API_KEY_HERE"


# --- [선택] 모델 이름 지정 ---
# LLM_PROVIDER를 'gemini'로 설정했을 때 사용할 모델 이름
GEMINI_MODEL="gemini-1.5-flash-latest"

# LLM_PROVIDER를 'local'로 설정했을 때 사용할 Ollama 모델 이름
# (터미널에서 'ollama list' 명령어로 설치된 모델 확인 가능)
ANALYSIS_LOCAL_MODEL="llama3"


# --- [선택] 주요 크롤링 설정 ---
# 한 사이트당 최대 크롤링할 페이지 수
MAX_PAGES_PER_SESSION=50

# LlmProcessingWorker가 콘텐츠를 유의미하다고 판단하는 최소 관련성 점수
RELEVANCE_THRESHOLD=0.6

# 각 페이지 요청 사이의 최소 지연 시간 (초). 대상 서버 부하를 줄입니다.
REQUEST_DELAY=1.0