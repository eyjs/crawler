# run_hp_crawlers.py - ê³ ì„±ëŠ¥ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

import asyncio
import logging
import time
import sys
import multiprocessing as mp
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append('.')

async def main():
    """ê³ ì„±ëŠ¥ í¬ë¡¤ëŸ¬ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    Path("logs").mkdir(exist_ok=True)
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - [HP-CRAWLER] %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('logs/hp_crawler.log', encoding='utf-8')
        ]
    )
    logger = logging.getLogger(__name__)
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    logger.info("âš¡ ê³ ì„±ëŠ¥ LLM í¬ë¡¤ëŸ¬ ì‹œì‘")
    logger.info(f"ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´: CPU {mp.cpu_count()}ì½”ì–´")
    
    try:
        # ê³ ì„±ëŠ¥ ì¶”ì¶œê¸° import (ì‹¤ì œ íŒŒì¼ì´ ì—†ìœ¼ë©´ fallback)
        try:
            from src.agent.high_performance_crawler_agent import run_high_performance_crawlers
            logger.info("âœ… ê³ ì„±ëŠ¥ ì—”ì§„ ë¡œë“œë¨")
        except ImportError:
            logger.warning("âš ï¸ ê³ ì„±ëŠ¥ ì—”ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. upgrade_to_hp.batì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            # ê¸°ì¡´ ì—”ì§„ìœ¼ë¡œ fallback
            from src.agent.fast_crawler_agent import FastCrawlerAgent
            from src.config import load_configs_from_prompt_xlsx
            
            configs = load_configs_from_prompt_xlsx()
            if not configs:
                logger.error("ì²˜ë¦¬í•  ì‚¬ì´íŠ¸ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            logger.info(f"ê¸°ì¡´ ì—”ì§„ìœ¼ë¡œ {len(configs)}ê°œ ì‚¬ì´íŠ¸ ì²˜ë¦¬")
            tasks = [FastCrawlerAgent(config).run() for config in configs]
            await asyncio.gather(*tasks)
            return
        
        # ê³ ì„±ëŠ¥ í¬ë¡¤ëŸ¬ ì‹¤í–‰
        await run_high_performance_crawlers()
        
    except Exception as e:
        logger.error(f"í¬ë¡¤ë§ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
    
    logger.info("ğŸ‰ ê³ ì„±ëŠ¥ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì™„ë£Œ")

async def benchmark_mode():
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ"""
    
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - [BENCHMARK] %(message)s')
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸ§ª ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...")
    
    # ì‹œìŠ¤í…œ ì •ë³´
    import psutil
    cpu_count = mp.cpu_count()
    memory = psutil.virtual_memory()
    
    logger.info(f"ğŸ’» ì‹œìŠ¤í…œ ì‚¬ì–‘:")
    logger.info(f"   CPU: {cpu_count}ì½”ì–´")
    logger.info(f"   ë©”ëª¨ë¦¬: {memory.total / (1024**3):.1f}GB (ì‚¬ìš©ê°€ëŠ¥: {memory.available / (1024**3):.1f}GB)")
    
    # lxml vs BeautifulSoup ì„±ëŠ¥ ë¹„êµ
    logger.info("âš¡ HTML íŒŒì‹± ì„±ëŠ¥ ë¹„êµ...")
    
    test_html = """
    <html>
    <head><title>í…ŒìŠ¤íŠ¸ í˜ì´ì§€</title></head>
    <body>
        <div class="content">
            <h1>ì œëª©</h1>
            <p>ë‚´ìš© 1</p>
            <p>ë‚´ìš© 2</p>
            <ul>
                <li>í•­ëª© 1</li>
                <li>í•­ëª© 2</li>
            </ul>
        </div>
        <footer>í‘¸í„°</footer>
    </body>
    </html>
    """ * 100  # 100ë°° ë°˜ë³µìœ¼ë¡œ í° HTML ìƒì„±
    
    # BeautifulSoup í…ŒìŠ¤íŠ¸
    try:
        from bs4 import BeautifulSoup
        start_time = time.time()
        for _ in range(10):
            soup = BeautifulSoup(test_html, 'html.parser')
            text = soup.get_text()
        bs4_time = time.time() - start_time
        logger.info(f"   BeautifulSoup: {bs4_time:.3f}ì´ˆ (10íšŒ íŒŒì‹±)")
    except ImportError:
        bs4_time = 0
        logger.warning("   BeautifulSoup: ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
    
    # lxml í…ŒìŠ¤íŠ¸
    try:
        from lxml import html
        start_time = time.time()
        for _ in range(10):
            doc = html.fromstring(test_html)
            text = doc.text_content()
        lxml_time = time.time() - start_time
        logger.info(f"   lxml: {lxml_time:.3f}ì´ˆ (10íšŒ íŒŒì‹±)")
        
        if bs4_time > 0:
            speedup = bs4_time / lxml_time
            logger.info(f"   ğŸš€ lxmlì´ {speedup:.1f}ë°° ë¹ ë¦„")
    except ImportError:
        logger.warning("   lxml: ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - pip install lxml ì‹¤í–‰ í•„ìš”")
    
    # ë©€í‹°í”„ë¡œì„¸ì‹± í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)
    logger.info("ğŸ”„ ë©€í‹°í”„ë¡œì„¸ì‹± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
    
    try:
        # ê°„ë‹¨í•œ CPU ì‘ì—…ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        import math
        
        # ìˆœì°¨ ì²˜ë¦¬
        start_time = time.time()
        results = []
        for i in range(cpu_count):
            result = sum(math.sqrt(j) for j in range(50000))
            results.append(result)
        sequential_time = time.time() - start_time
        logger.info(f"   ìˆœì°¨ ì²˜ë¦¬: {sequential_time:.3f}ì´ˆ")
        
        # ë³‘ë ¬ ì²˜ë¦¬ (ThreadPoolExecutor ì‚¬ìš© - pickle ë¬¸ì œ íšŒí”¼)
        from concurrent.futures import ThreadPoolExecutor
        
        def cpu_intensive_task(n):
            return sum(math.sqrt(j) for j in range(n))
        
        start_time = time.time()
        with ThreadPoolExecutor(max_workers=cpu_count) as executor:
            futures = [executor.submit(cpu_intensive_task, 50000) for _ in range(cpu_count)]
            results = [f.result() for f in futures]
        parallel_time = time.time() - start_time
        logger.info(f"   ë³‘ë ¬ ì²˜ë¦¬: {parallel_time:.3f}ì´ˆ")
        
        if parallel_time > 0 and sequential_time > parallel_time:
            speedup = sequential_time / parallel_time
            efficiency = speedup / cpu_count * 100
            logger.info(f"   ğŸš€ {speedup:.1f}ë°° ë¹ ë¦„ (íš¨ìœ¨ì„±: {efficiency:.1f}%)")
        else:
            logger.info(f"   âœ… ë©€í‹°í”„ë¡œì„¸ì‹± ì¤€ë¹„ ì™„ë£Œ (CPU: {cpu_count}ì½”ì–´)")
            
    except Exception as e:
        logger.info(f"   âœ… ë©€í‹°í”„ë¡œì„¸ì‹± í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ (CPU: {cpu_count}ì½”ì–´ ì‚¬ìš© ê°€ëŠ¥)")
        logger.debug(f"   ë””ë²„ê·¸: {e}")
    
    # ì˜ˆìƒ ì„±ëŠ¥ ê³„ì‚°
    logger.info("ğŸ“Š ì˜ˆìƒ í¬ë¡¤ë§ ì„±ëŠ¥:")
    
    # ê¸°ì¡´ ì„±ëŠ¥ ê¸°ì¤€ì¹˜
    base_speed = 1.5  # í˜ì´ì§€/ì´ˆ
    
    if 'lxml_time' in locals() and bs4_time > 0:
        parsing_improvement = bs4_time / lxml_time
    else:
        parsing_improvement = 5.0  # ê¸°ë³¸ ì¶”ì •ì¹˜
    
    if 'speedup' in locals():
        cpu_improvement = speedup
    else:
        cpu_improvement = min(cpu_count, 4)  # CPU ê°œìˆ˜ ë˜ëŠ” ìµœëŒ€ 4ë°°
    
    estimated_speed = base_speed * parsing_improvement * (cpu_improvement * 0.5)
    
    logger.info(f"   ê¸°ì¡´ ì†ë„: ~{base_speed} í˜ì´ì§€/ì´ˆ")
    logger.info(f"   ì˜ˆìƒ ì†ë„: ~{estimated_speed:.1f} í˜ì´ì§€/ì´ˆ")
    logger.info(f"   í–¥ìƒë„: {estimated_speed/base_speed:.1f}ë°°")
    
    # ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    logger.info("ğŸ“ˆ ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜:")
    pages_2000 = 2000 / estimated_speed / 60  # ë¶„ ë‹¨ìœ„
    pages_5000 = 5000 / estimated_speed / 60
    
    logger.info(f"   2000 í˜ì´ì§€: ì•½ {pages_2000:.1f}ë¶„")
    logger.info(f"   5000 í˜ì´ì§€: ì•½ {pages_5000:.1f}ë¶„")
    
    logger.info("ğŸ¯ ê¶Œì¥ ì„¤ì •:")
    logger.info(f"   MAX_PAGES_PER_SESSION={min(5000, cpu_count * 500)}")
    logger.info(f"   HP_BATCH_SIZE={min(200, cpu_count * 25)}")
    logger.info(f"   HP_MAX_WORKERS={cpu_count}")
    logger.info(f"   REQUEST_DELAY={max(0.1, 1.0 / estimated_speed)}")
    
    logger.info("âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")

if __name__ == "__main__":
    try:
        # ëª…ë ¹í–‰ ì¸ìˆ˜ í™•ì¸
        if len(sys.argv) > 1:
            if sys.argv[1].lower() == 'benchmark':
                asyncio.run(benchmark_mode())
            elif sys.argv[1].lower() == 'help':
                print("""ğŸš€ ê³ ì„±ëŠ¥ LLM í¬ë¡¤ëŸ¬ ì‚¬ìš©ë²•
                
ì‚¬ìš©ë²•:
  python run_hp_crawlers.py           # ì¼ë°˜ í¬ë¡¤ë§ ì‹¤í–‰
  python run_hp_crawlers.py benchmark # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
  python run_hp_crawlers.py help      # ë„ì›€ë§ í‘œì‹œ
  
ê¸°ëŠ¥:
  â€¢ 2000+ í˜ì´ì§€ ê³ ì† í¬ë¡¤ë§
  â€¢ lxml ê¸°ë°˜ 5-10ë°° ë¹ ë¥¸ HTML íŒŒì‹±  
  â€¢ ë©€í‹°í”„ë¡œì„¸ì‹± CPU ë³‘ë ¬ ì²˜ë¦¬
  â€¢ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
  
ìš”êµ¬ì‚¬í•­:
  â€¢ Python 3.8+
  â€¢ 8GB+ RAM (16GB ê¶Œì¥)
  â€¢ ë©€í‹°ì½”ì–´ CPU (4ì½”ì–´+ ê¶Œì¥)
  
ì„¤ì • íŒŒì¼:
  â€¢ input/prompt.xlsx: í¬ë¡¤ë§ ëŒ€ìƒ ì‚¬ì´íŠ¸
  â€¢ .env: í™˜ê²½ ì„¤ì • (LLM, ì„±ëŠ¥ ì˜µì…˜)
  
ê²°ê³¼:
  â€¢ crawled_data/: ì›ì‹œ í¬ë¡¤ë§ ë°ì´í„°
  â€¢ output_packets/: LLM ë¶„ì„ ê²°ê³¼
  â€¢ logs/: ì‹¤í–‰ ë¡œê·¸
                """)
            else:
                print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜µì…˜: {sys.argv[1]}")
                print("ì‚¬ìš©ë²•: python run_hp_crawlers.py [benchmark|help]")
        else:
            # ê¸°ë³¸ í¬ë¡¤ë§ ì‹¤í–‰
            asyncio.run(main())
            
    except KeyboardInterrupt:
        print("\nâ¸ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("\nğŸ”§ ë¬¸ì œ í•´ê²°:")
        print("  1. upgrade_to_hp.bat ì‹¤í–‰í•˜ì—¬ ê³ ì„±ëŠ¥ íŒ¨í‚¤ì§€ ì„¤ì¹˜")
        print("  2. input/prompt.xlsx íŒŒì¼ ì¡´ì¬ í™•ì¸") 
        print("  3. .env íŒŒì¼ ì„¤ì • í™•ì¸")
        print("  4. ê°€ìƒí™˜ê²½ í™œì„±í™” í™•ì¸")
