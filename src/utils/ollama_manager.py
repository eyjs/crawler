#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ollama/Llama3 ì„¤ì¹˜ ë° ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°
ë¡œì»¬ LLM í™˜ê²½ ìë™ êµ¬ì„±
"""

import os
import sys
import platform
import subprocess
import requests
import time
from pathlib import Path
from loguru import logger
import json



class OllamaManager:
    """Ollama/Llama3 ì„¤ì¹˜ ë° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.platform = platform.system().lower()
        self.ollama_base_url = "http://localhost:11434"
        self.model_name = "llama3"
        
    def check_ollama_installed(self):
        """Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        try:
            result = subprocess.run(['ollama', '--version'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                version = result.stdout.strip()
                logger.info(f"âœ… Ollama ì„¤ì¹˜ í™•ì¸: {version}")
                return True
        except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.CalledProcessError):
            pass
        
        logger.warning("âš ï¸ Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤")
        return False
    
    def install_ollama(self):
        """í”Œë«í¼ë³„ Ollama ì„¤ì¹˜"""
        logger.info(f"ğŸ“¦ {self.platform} í™˜ê²½ì— Ollama ì„¤ì¹˜ ì‹œì‘...")
        
        try:
            if self.platform == 'windows':
                return self._install_ollama_windows()
            elif self.platform == 'darwin':  # macOS
                return self._install_ollama_macos()
            elif self.platform == 'linux':
                return self._install_ollama_linux()
            else:
                logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í”Œë«í¼: {self.platform}")
                return False
        except Exception as e:
            logger.error(f"âŒ Ollama ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
            return False
    
    def _install_ollama_windows(self):
        """Windowsìš© Ollama ì„¤ì¹˜"""
        # Chocolatey ì‚¬ìš© ì‹œë„
        try:
            result = subprocess.run(['choco', 'install', 'ollama', '-y'], 
                                  capture_output=True, text=True, timeout=300)
            if result.returncode == 0:
                logger.success("âœ… Chocolateyë¡œ Ollama ì„¤ì¹˜ ì™„ë£Œ")
                return True
        except (FileNotFoundError, subprocess.TimeoutExpired):
            pass
        
        # ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜ ì•ˆë‚´
        logger.info("ğŸ’¡ Windowsì—ì„œ Ollama ìˆ˜ë™ ì„¤ì¹˜ ë°©ë²•:")
        logger.info("   1. https://ollama.ai/download ë°©ë¬¸")
        logger.info("   2. Windowsìš© ì„¤ì¹˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
        logger.info("   3. ì„¤ì¹˜ í›„ ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰")
        
        try:
            response = input("Ollamaë¥¼ ì„¤ì¹˜í–ˆë‚˜ìš”? (y/n): ").lower().strip()
            return response == 'y'
        except (KeyboardInterrupt, EOFError):
            return False
    
    def _install_ollama_macos(self):
        """macOSìš© Ollama ì„¤ì¹˜"""
        # Homebrew ì‚¬ìš© ì‹œë„
        try:
            result = subprocess.run(['brew', 'install', 'ollama'], 
                                  capture_output=True, text=True, timeout=300)
            if result.returncode == 0:
                logger.success("âœ… Homebrewë¡œ Ollama ì„¤ì¹˜ ì™„ë£Œ")
                return True
        except (FileNotFoundError, subprocess.TimeoutExpired):
            pass
        
        # ìˆ˜ë™ ì„¤ì¹˜ ì•ˆë‚´
        logger.info("ğŸ’¡ macOSì—ì„œ Ollama ìˆ˜ë™ ì„¤ì¹˜ ë°©ë²•:")
        logger.info("   1. í„°ë¯¸ë„ì—ì„œ: curl -fsSL https://ollama.ai/install.sh | sh")
        logger.info("   2. ë˜ëŠ” https://ollama.ai/download ì—ì„œ ì•± ë‹¤ìš´ë¡œë“œ")
        
        try:
            response = input("Ollamaë¥¼ ì„¤ì¹˜í–ˆë‚˜ìš”? (y/n): ").lower().strip()
            return response == 'y'
        except (KeyboardInterrupt, EOFError):
            return False
    
    def _install_ollama_linux(self):
        """Linuxìš© Ollama ì„¤ì¹˜"""
        try:
            # ê³µì‹ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            result = subprocess.run(['curl', '-fsSL', 'https://ollama.ai/install.sh'], 
                                  capture_output=True, text=True, timeout=60)
            if result.returncode == 0:
                # ìŠ¤í¬ë¦½íŠ¸ë¥¼ bashë¡œ ì‹¤í–‰
                process = subprocess.run(['bash'], input=result.stdout, 
                                       text=True, timeout=300)
                if process.returncode == 0:
                    logger.success("âœ… Linuxì— Ollama ì„¤ì¹˜ ì™„ë£Œ")
                    return True
        except (subprocess.TimeoutExpired, subprocess.CalledProcessError) as e:
            logger.error(f"ìë™ ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
        
        # ìˆ˜ë™ ì„¤ì¹˜ ì•ˆë‚´
        logger.info("ğŸ’¡ Linuxì—ì„œ Ollama ìˆ˜ë™ ì„¤ì¹˜ ë°©ë²•:")
        logger.info("   í„°ë¯¸ë„ì—ì„œ: curl -fsSL https://ollama.ai/install.sh | sh")
        
        try:
            response = input("Ollamaë¥¼ ì„¤ì¹˜í–ˆë‚˜ìš”? (y/n): ").lower().strip()
            return response == 'y'
        except (KeyboardInterrupt, EOFError):
            return False
    
    def check_ollama_running(self):
        """Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸"""
        try:
            response = requests.get(f"{self.ollama_base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                logger.info("âœ… Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ ì¤‘")
                return True
        except requests.exceptions.RequestException:
            pass
        
        logger.warning("âš ï¸ Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ")
        return False
    
    def start_ollama_service(self):
        """Ollama ì„œë¹„ìŠ¤ ì‹œì‘"""
        logger.info("ğŸš€ Ollama ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘...")
        
        try:
            if self.platform == 'windows':
                # Windowsì—ì„œ ë°±ê·¸ë¼ìš´ë“œë¡œ ollama serve ì‹¤í–‰
                subprocess.Popen(['ollama', 'serve'], 
                               creationflags=subprocess.CREATE_NO_WINDOW)
            else:
                # macOS/Linuxì—ì„œ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰
                subprocess.Popen(['ollama', 'serve'], 
                               stdout=subprocess.DEVNULL, 
                               stderr=subprocess.DEVNULL)
            
            # ì„œë¹„ìŠ¤ ì‹œì‘ ëŒ€ê¸°
            for i in range(30):  # ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
                time.sleep(1)
                if self.check_ollama_running():
                    logger.success("âœ… Ollama ì„œë¹„ìŠ¤ ì‹œì‘ ì™„ë£Œ")
                    return True
                
            logger.error("âŒ Ollama ì„œë¹„ìŠ¤ ì‹œì‘ íƒ€ì„ì•„ì›ƒ")
            return False
            
        except Exception as e:
            logger.error(f"âŒ Ollama ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨: {e}")
            return False
    
    def check_model_installed(self, model_name=None):
        """íŠ¹ì • ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        if model_name is None:
            model_name = self.model_name
            
        try:
            response = requests.get(f"{self.ollama_base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                models = response.json().get('models', [])
                for model in models:
                    if model_name in model.get('name', ''):
                        logger.info(f"âœ… ëª¨ë¸ '{model_name}' ì„¤ì¹˜ í™•ì¸")
                        return True
        except Exception as e:
            logger.error(f"ëª¨ë¸ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        logger.warning(f"âš ï¸ ëª¨ë¸ '{model_name}'ì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        return False
    
    def install_model(self, model_name=None):
        """ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜"""
        if model_name is None:
            model_name = self.model_name
            
        logger.info(f"ğŸ“¥ ëª¨ë¸ '{model_name}' ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        logger.info("â³ ì´ ì‘ì—…ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ìˆ˜ GB ë‹¤ìš´ë¡œë“œ)")
        
        try:
            # ollama pull ëª…ë ¹ ì‹¤í–‰
            process = subprocess.Popen(
                ['ollama', 'pull', model_name],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            # ì‹¤ì‹œê°„ ì¶œë ¥ í‘œì‹œ
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    print(output.strip())
            
            if process.returncode == 0:
                logger.success(f"âœ… ëª¨ë¸ '{model_name}' ì„¤ì¹˜ ì™„ë£Œ")
                return True
            else:
                logger.error(f"âŒ ëª¨ë¸ '{model_name}' ì„¤ì¹˜ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def test_model(self, model_name=None):
        """ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        if model_name is None:
            model_name = self.model_name
            
        logger.info(f"ğŸ§ª ëª¨ë¸ '{model_name}' í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        test_prompt = "Hello! Please respond with just 'OK' to confirm you're working."
        
        try:
            payload = {
                "model": model_name,
                "prompt": test_prompt,
                "stream": False
            }
            
            response = requests.post(
                f"{self.ollama_base_url}/api/generate",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                model_response = result.get('response', '').strip()
                logger.info(f"ğŸ“ ëª¨ë¸ ì‘ë‹µ: {model_response}")
                logger.success(f"âœ… ëª¨ë¸ '{model_name}' í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                return True
            else:
                logger.error(f"âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def setup_complete_environment(self):
        """ì „ì²´ Ollama/Llama3 í™˜ê²½ ì„¤ì •"""
        logger.info("ğŸ”§ Ollama/Llama3 í™˜ê²½ ì„¤ì • ì‹œì‘")
        
        # 1. Ollama ì„¤ì¹˜ í™•ì¸
        if not self.check_ollama_installed():
            if not self.install_ollama():
                logger.error("âŒ Ollama ì„¤ì¹˜ ì‹¤íŒ¨")
                return False
        
        # 2. ì„œë¹„ìŠ¤ ì‹¤í–‰ í™•ì¸
        if not self.check_ollama_running():
            if not self.start_ollama_service():
                logger.error("âŒ Ollama ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨")
                return False
        
        # 3. ëª¨ë¸ ì„¤ì¹˜ í™•ì¸
        if not self.check_model_installed():
            if not self.install_model():
                logger.error("âŒ ëª¨ë¸ ì„¤ì¹˜ ì‹¤íŒ¨")
                return False
        
        # 4. ëª¨ë¸ í…ŒìŠ¤íŠ¸
        if not self.test_model():
            logger.error("âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return False
        
        logger.success("ğŸ‰ Ollama/Llama3 í™˜ê²½ ì„¤ì • ì™„ë£Œ!")
        return True


def check_env_local():
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ LLM_PROVIDERê°€ localì¸ì§€ í™•ì¸"""
    try:
        # .env íŒŒì¼ ì½ê¸°
        env_file = Path('.env')
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # LLM_PROVIDER ì°¾ê¸°
            for line in content.split('\n'):
                line = line.strip()
                if line.startswith('LLM_PROVIDER='):
                    value = line.split('=', 1)[1].strip().strip('"').strip("'")
                    return value.lower() == 'local'
        
        # ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ í™•ì¸
        return os.getenv('LLM_PROVIDER', '').lower() == 'local'
        
    except Exception as e:
        logger.error(f"í™˜ê²½ ì„¤ì • í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸ¤– Ollama/Llama3 ì„¤ì • ìœ í‹¸ë¦¬í‹°")
    
    # í™˜ê²½ ì„¤ì • í™•ì¸
    if not check_env_local():
        logger.info("ğŸ’¡ LLM_PROVIDERê°€ 'local'ì´ ì•„ë‹ˆë¯€ë¡œ Ollama ì„¤ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤")
        return True
    
    # Ollama í™˜ê²½ ì„¤ì •
    manager = OllamaManager()
    return manager.setup_complete_environment()


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
